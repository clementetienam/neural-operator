{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W6UNk6TG-uVo",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Link to datasets: https://drive.google.com/drive/folders/149NUN6AWG6I-CINW_T1HNn-BBxNPqLVW?usp=sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/skp340/opt/anaconda3/envs/ndmd-env/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.parameter import Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from functools import reduce\n",
    "from functools import partial\n",
    "import operator\n",
    "import os\n",
    "from timeit import default_timer\n",
    "\n",
    "import einops\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class LpLoss(object):\n",
    "    \"\"\"Computes relative and absolute L^{p} loss functions.\"\"\"\n",
    "\n",
    "    def __init__(self, d=2, p=2, size_average=True, reduction=True):\n",
    "        super(LpLoss, self).__init__()\n",
    "\n",
    "        assert d > 0 and p > 0\n",
    "\n",
    "        self.dim = d\n",
    "        self.p = p\n",
    "        self.reduction = reduction\n",
    "        self.size_average = size_average\n",
    "\n",
    "    def abs(self, x, y):\n",
    "        \"\"\"Computes absolute error, assuming a uniform mesh.\"\"\"\n",
    "\n",
    "        batch_size = x.shape[0]\n",
    "\n",
    "        h = 1.0 / (x.shape[1] - 1.0)\n",
    "\n",
    "        all_norms = (h**(self.dim/self.p))*torch.norm(\n",
    "                            x.view(batch_size,-1) - y.view(batch_size,-1),\n",
    "                            self.p,\n",
    "                            1,) # axis\n",
    "\n",
    "        if self.reduction:\n",
    "            if self.size_average:\n",
    "                return torch.mean(all_norms)\n",
    "            else:\n",
    "                return torch.sum(all_norms)\n",
    "\n",
    "        return all_norms\n",
    "\n",
    "    def rel(self, x, y):\n",
    "        \"\"\"Computes relative error.\"\"\"\n",
    "\n",
    "        num_examples = x.size()[0]\n",
    "\n",
    "        diff_norms = torch.norm(\n",
    "                        x.reshape(num_examples,-1) - y.reshape(num_examples,-1),\n",
    "                        self.p,\n",
    "                        1,) # axis\n",
    "        y_norms = torch.norm(y.reshape(num_examples,-1),\n",
    "                            self.p,\n",
    "                            1,)\n",
    "\n",
    "        if self.reduction:\n",
    "            if self.size_average:\n",
    "                return torch.mean(diff_norms/y_norms)\n",
    "            else:\n",
    "                return torch.sum(diff_norms/y_norms)\n",
    "\n",
    "        return diff_norms/y_norms\n",
    "\n",
    "    def __call__(self, x, y):\n",
    "        return self.rel(x, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class MatReader(object):\n",
    "    def __init__(self, file_path, to_torch=True, to_cuda=False, to_float=True):\n",
    "        super(MatReader, self).__init__()\n",
    "\n",
    "        self.to_torch = to_torch\n",
    "        self.to_cuda = to_cuda\n",
    "        self.to_float = to_float\n",
    "\n",
    "        self.file_path = file_path\n",
    "\n",
    "        self.data = None\n",
    "        self.old_mat = None\n",
    "        self._load_file()\n",
    "\n",
    "    def _load_file(self):\n",
    "        try:\n",
    "            self.data = scipy.io.loadmat(self.file_path)\n",
    "            self.old_mat = True\n",
    "        except:\n",
    "            self.data = h5py.File(self.file_path)\n",
    "            self.old_mat = False\n",
    "\n",
    "    def load_file(self, file_path):\n",
    "        self.file_path = file_path\n",
    "        self._load_file()\n",
    "\n",
    "    def read_field(self, field):\n",
    "        x = self.data[field]\n",
    "\n",
    "        if not self.old_mat:\n",
    "            x = x[()]\n",
    "            x = np.transpose(x, axes=range(len(x.shape) - 1, -1, -1))\n",
    "\n",
    "        if self.to_float:\n",
    "            x = x.astype(np.float32)\n",
    "\n",
    "        if self.to_torch:\n",
    "            x = torch.from_numpy(x)\n",
    "\n",
    "            if self.to_cuda:\n",
    "                x = x.cuda()\n",
    "\n",
    "        return x\n",
    "\n",
    "    def set_cuda(self, to_cuda):\n",
    "        self.to_cuda = to_cuda\n",
    "\n",
    "    def set_torch(self, to_torch):\n",
    "        self.to_torch = to_torch\n",
    "\n",
    "    def set_float(self, to_float):\n",
    "        self.to_float = to_float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class UnitGaussianNormalizer(object):\n",
    "    \"\"\"Applies pointwise Gaussian normalization to an input tensor.\"\"\"\n",
    "    def __init__(self, x, eps=0.00001):\n",
    "        super(UnitGaussianNormalizer, self).__init__()\n",
    "        \"\"\"Args:\n",
    "            x: tensor of shape (ntrain X n) or (ntrain X T X n) or\n",
    "                (ntrain X n X T)\n",
    "        \"\"\"\n",
    "        self.mean = torch.mean(x, 0)\n",
    "        self.std = torch.std(x, 0)\n",
    "        self.eps = eps\n",
    "\n",
    "    def encode(self, x):\n",
    "        x = (x - self.mean) / (self.std + self.eps)\n",
    "        return x\n",
    "\n",
    "    def decode(self, x, sample_idx=None):\n",
    "        if sample_idx is None:\n",
    "            std = self.std + self.eps # n\n",
    "            mean = self.mean\n",
    "        else:\n",
    "            if len(self.mean.shape) == len(sample_idx[0].shape):\n",
    "                std = self.std[sample_idx] + self.eps  # (batch X n)\n",
    "                mean = self.mean[sample_idx]\n",
    "            if len(self.mean.shape) > len(sample_idx[0].shape):\n",
    "                std = self.std[:,sample_idx]+ self.eps # (T X batch X n)\n",
    "                mean = self.mean[:,sample_idx]\n",
    "\n",
    "        # x in shape of (batch X n) or (T X batch X n)\n",
    "        x = (x * std) + mean\n",
    "        return x\n",
    "\n",
    "    def cuda(self):\n",
    "        self.mean = self.mean.cuda()\n",
    "        self.std = self.std.cuda()\n",
    "\n",
    "    def cpu(self):\n",
    "        self.mean = self.mean.cpu()\n",
    "        self.std = self.std.cpu()\n",
    "\n",
    "    def to(self, device):\n",
    "        self.mean = self.mean.to(device)\n",
    "        self.std = self.std.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def mat_to_tensor1d(TRAIN_PATH, \n",
    "                  TEST_PATH, \n",
    "                  ss_rate, \n",
    "                  x_field, y_field, \n",
    "                  vsamples=None, \n",
    "                  normalize=False):\n",
    "    \"\"\"Converts .mat file contents to torch tensors.\n",
    "\n",
    "        Args:\n",
    "            TRAIN_PATH: list of .mat file names to concatenate into training \n",
    "                        tensors\n",
    "            TEST_PATH: list of .mat file names to concatenate into test tensors\n",
    "            ss_rate: [train subsampling rate, test rate]\n",
    "            x_field, y_field: names of fields in the .mat file\n",
    "            vsamples: [ntest, ntrain]\n",
    "            print: Print log contents to the console; default = True\n",
    "            normalize: Apply normalization to the tensors; default = False\n",
    "    \"\"\"\n",
    "    t1 = default_timer()\n",
    "\n",
    "    reader = MatReader(TRAIN_PATH)\n",
    "    x_data = reader.read_field(x_field)\n",
    "    y_data = reader.read_field(y_field)\n",
    "    dimension = len(x_data.shape) - 1\n",
    "    \n",
    "    mat_info = (\"input signal vector samples: {}\\n\"\n",
    "                   \"output signal vector samples: {}\\n\"\n",
    "                   \"input signal entry samples: {}\\n\"\n",
    "                   \"output signal entry samples: {}\\n\"\n",
    "                   \"signal dimension: {}\\n\\n\"\n",
    "                  ).format(x_data.shape[0], \n",
    "                           y_data.shape[0], \n",
    "                           x_data.shape[1], \n",
    "                           y_data.shape[1], \n",
    "                           dimension)\n",
    "\n",
    "    ntrain = vsamples[0]\n",
    "    ntest = vsamples[1]\n",
    "\n",
    "    full_res = x_data.shape[1]\n",
    "    tr_ss = ss_rate[0]\n",
    "    tst_ss = ss_rate[1]\n",
    "    tr_esamples = int(((full_res - 1)/tr_ss) + 1)\n",
    "\n",
    "    x_train = x_data[ntrain:,::tr_ss][:,:tr_esamples]\n",
    "    y_train = y_data[ntrain:,::tr_ss][:,:tr_esamples]\n",
    "\n",
    "    if TRAIN_PATH != TEST_PATH:\n",
    "        # using separate test/train datasets\n",
    "        test_reader = MatReader(TEST_PATH)\n",
    "        x_test = test_reader.read_field(x_field)\n",
    "        y_test = test_reader.read_field(y_field)\n",
    "\n",
    "        full_res = x_test.shape[1]\n",
    "        tst_esamples = int(((full_res - 1)/tst_ss) + 1)\n",
    "\n",
    "        x_test = x_test[ntest:,::tst_ss][:,:tst_esamples]\n",
    "        y_test = y_test[ntest:,::tst_ss][:,:tst_esamples]\n",
    "\n",
    "    else:\n",
    "        full_res = x_data.shape[1]\n",
    "        tst_esamples = int(((full_res - 1)/tst_ss) + 1)\n",
    "\n",
    "        # same dataset; use last (ntest) samples\n",
    "        x_test = x_data[-ntest:,::tst_ss][:,:tst_esamples]\n",
    "        y_test = y_data[-ntest:,::tst_ss][:,:tst_esamples]\n",
    "\n",
    "        \n",
    "    ds_info = (\"training dataset: {}\\n\"\n",
    "                    \"test dataset: {}\\n\\n\"\n",
    "                    \"input train samples: {}\\n\"\n",
    "                    \"output train samples: {}\\n\"\n",
    "                    \"input train resolution: {}\\n\"\n",
    "                    \"output train resolution: {}\\n\\n\"\n",
    "                    \"input test samples: {}\\n\"\n",
    "                    \"output test samples: {}\\n\"\n",
    "                    \"input test resolution: {}\\n\"\n",
    "                    \"output test resolution: {}\\n\\n\"\n",
    "    ).format(TRAIN_PATH,\n",
    "             TEST_PATH,\n",
    "             x_train.shape[0], \n",
    "             y_train.shape[0], \n",
    "             x_train.shape[1],\n",
    "             y_train.shape[1],\n",
    "             x_test.shape[0],\n",
    "             y_test.shape[0],\n",
    "             x_test.shape[1],\n",
    "             y_test.shape[1])\n",
    "\n",
    "\n",
    "    t2 = default_timer()\n",
    "    \n",
    "    return x_train, y_train, x_test, y_test, mat_info, ds_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def complex_mul1d(a, b):\n",
    "    \"\"\"Performs complex multiplication between two input tensors.\n",
    "\n",
    "    Args:\n",
    "    a: tensor of shape (batch, in_channel, x)\n",
    "    b: tensor of shape (in_channel, out_channel, x)\n",
    "\n",
    "    return: tensor of form (batch, out_channel, x)\n",
    "    \"\"\"\n",
    "    return torch.einsum(\"bix,iox->box\", a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class SpectralConv1d(nn.Module):\n",
    "    def __init__(self, \n",
    "                 in_channels, \n",
    "                 out_channels, \n",
    "                 modes, \n",
    "                 trainable=True):\n",
    "        super(SpectralConv1d, self).__init__()\n",
    "\n",
    "        \"\"\"Applies FFT, linear transform, and inverse FFT.\n",
    "        \n",
    "        Args:\n",
    "            in_channels: number of input channels\n",
    "            out_channels: number of output channels\n",
    "            modes: number of Fourier modes to multiply\n",
    "            train: make weights trainable parameters\n",
    "        \"\"\"\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.modes = modes\n",
    "        self.trainable = trainable\n",
    "        self.scale = (1 / (in_channels*out_channels))\n",
    "\n",
    "        self.weights = nn.Parameter(self.scale *\n",
    "                                    torch.rand(self.in_channels, \n",
    "                                               self.out_channels, \n",
    "                                                self.modes, \n",
    "                                                dtype=torch.cfloat))\n",
    "        self.weights.requires_grad = trainable\n",
    "\n",
    "    def forward(self, x):\n",
    "        batchsize = x.shape[0]\n",
    "        \n",
    "        # Compute Fourier coeffcients up to factor of e^(-constant)\n",
    "        x_ft = torch.fft.rfft(x)\n",
    "\n",
    "        # Multiply relevant Fourier modes\n",
    "        out_ft = complex_mul1d(x_ft[:, :, :self.modes], \n",
    "                               self.weights)\n",
    "\n",
    "        # Return to physical space\n",
    "        x = torch.fft.irfft(out_ft,n=x.size(-1))\n",
    "        \n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class FourierBlock1d(nn.Module):\n",
    "    \"\"\"Fourier kernel block implementing\n",
    "                    u' = (W + K)(u),\n",
    "       where W is defined by a convolution and K is defined by \n",
    "       a spectral convolution in Fourier space.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 width,\n",
    "                 modes,\n",
    "                 nonlinearity,\n",
    "                 trainable=True):\n",
    "        super(FourierBlock1d, self).__init__()\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            modes: Number of Fourier modes to multiply (at most floor(N/2) + 1)\n",
    "            width: Dimension of lifting transform performed by first layer\n",
    "            nonlinearity: Component-wise nonlinear activation\n",
    "            trainable: Whether or not the weights are trainable parameters; \n",
    "                   default = True\n",
    "        \"\"\"\n",
    "        self.width = width\n",
    "        self.modes = modes\n",
    "        self.trainable = trainable\n",
    "        self.nonlinearity = nonlinearity\n",
    "        \n",
    "        # call signature SpectralConv2d(in_dim, out_dim, modes_x)\n",
    "        self.R = SpectralConv1d(self.width,\n",
    "                                self.width,\n",
    "                                self.modes,\n",
    "                                self.trainable)\n",
    "        \n",
    "        # call signature ConvNd(in_dim, out_dim, kernel_size)\n",
    "        self.w = nn.Conv1d(self.width, self.width, 1) # TODO: implement with linear layer instead\n",
    "        self.w.weight.requires_grad = trainable\n",
    "        self.w.bias.requires_grad = trainable\n",
    "        \n",
    "    def forward(self, x):\n",
    "\n",
    "        # x = 'b c x'\n",
    "        Rx = self.R(x)\n",
    "\n",
    "        # x = 'b c x'\n",
    "        wx = self.w(x)\n",
    "\n",
    "        if self.nonlinearity == None:\n",
    "            return Rx + wx\n",
    "        else:\n",
    "            return self.nonlinearity(Rx + wx)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class FourierKernel1d(nn.Module):\n",
    "    \"\"\"The Fourier kernel containing a specified number of Fourier blocks.\n",
    "    \n",
    "    1. Lift the input to the desired channel dimension by self.fc0.\n",
    "    2. Apply specified number of iterations of the operator \n",
    "                            u' = (W + K)(u)\n",
    "    3. Project from the channel space to the output space by self.fc1 \n",
    "        and self.fc2.\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "                 n_blocks, \n",
    "                 modes, \n",
    "                 width,\n",
    "                 nonlinearity,\n",
    "                 trainable):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            blocks: Number of kernel integral transform blocks\n",
    "            modes: Number of Fourier modes to multiply (at most floor(N/2) + 1)\n",
    "            width: Dimension of lifting transform performed by first layer\n",
    "            nonlinearity: Component-wise nonlinear activation\n",
    "        \"\"\"\n",
    "        super(FourierKernel1d, self).__init__()\n",
    "\n",
    "        self.n_blocks = n_blocks\n",
    "        self.modes = modes\n",
    "        self.width = width\n",
    "        self.nonlin = nonlinearity\n",
    "        self.trainable = trainable\n",
    "\n",
    "        # input channel is 2: (a(x), x)\n",
    "        self.fc0 = nn.Linear(2, self.width)\n",
    "        \n",
    "        self.blocks = nn.ModuleList()\n",
    "        \n",
    "        for b in range(self.n_blocks):\n",
    "            \n",
    "            if b == self.n_blocks - 1:\n",
    "                self.blocks.append(FourierBlock1d(\n",
    "                                        self.width,\n",
    "                                        self.modes,\n",
    "                                        None,\n",
    "                                        trainable))\n",
    "            else:\n",
    "                self.blocks.append(FourierBlock1d(\n",
    "                                            self.width,\n",
    "                                            self.modes,\n",
    "                                            self.nonlin,\n",
    "                                            trainable))\n",
    "        \n",
    "        # return to input space\n",
    "        self.fc1 = nn.Linear(self.width, self.width*self.n_blocks)\n",
    "        self.fc2 = nn.Linear(self.width*self.n_blocks, 1)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"Apply kernel transform to input data.\n",
    "        Args:\n",
    "            x: the solution of the coefficient function and locations \n",
    "                    (a(x), x); shape (batchsize, x=s, c=2)\n",
    "            \n",
    "            return: solution u(x); shape (batchsize, x=s, c=1)\n",
    "        \"\"\"\n",
    "        batchsize = x.shape[0]\n",
    "        \n",
    "        x = self.fc0(x)\n",
    "        \n",
    "        x = einops.rearrange(x, 'b x c -> b c x')\n",
    "\n",
    "        for block in self.blocks:\n",
    "            x = block(x)\n",
    "\n",
    "        x = einops.rearrange(x, 'b c x -> b x c')\n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class OperatorNet(nn.Module):    \n",
    "    def __init__(self, \n",
    "                 kernel, \n",
    "                 name=None):\n",
    "        super(OperatorNet, self).__init__()\n",
    "        \n",
    "        self.kernel = kernel\n",
    "        self.modelname = name\n",
    "        \n",
    "        c = 0\n",
    "        for p in self.parameters():\n",
    "            c += reduce(operator.mul, list(p.size()))\n",
    "        self.param_count = c\n",
    "        \n",
    "    def param_count(self):\n",
    "        return self.param_count\n",
    "    \n",
    "    def name(self):\n",
    "        return \"model: {}\".format(self.modelname)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.kernel(x)\n",
    "        return x.squeeze()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "PATH = \"../data/\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Set up properties and I/O of training run"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "train_ds_name = \"burgers_e4096_N1000_g2.5_t7_v100_s49_per_2104291732\"\n",
    "test_dir = \"burgers_e4096_N400_g2.5_t7_v100_s49_dir_2104300546\"\n",
    "test_per = \"burgers_e4096_N400_g2.5_t7_v100_s49_per_2104300508\"\n",
    "test_neu = \"burgers_e4096_N400_g2.5_t7_v100_s49_neu_2104300435\"\n",
    "\n",
    "TEST_PATH = [PATH+test_dir+'.mat',\n",
    "             PATH+test_per+'.mat',\n",
    "             PATH+test_neu+'.mat']\n",
    "\"\"\"\n",
    "\n",
    "train_ds_name = 'burgers_data_R10_original'\n",
    "test_ds_name = \"burgers_data_R10_original\"\n",
    "test_ds_name = 'burgers_e4096_N400_g2.5_t7_v100_s49_per_2104300508'\n",
    "TRAIN_PATH = PATH+train_ds_name+'.mat'\n",
    "TEST_PATH = PATH+test_ds_name+'.mat'\n",
    "\n",
    "# field name in the matlab file\n",
    "x_name = \"a\"\n",
    "y_name = \"u\"\n",
    "\n",
    "# dataset properties\n",
    "ss_rate = [8, 8]\n",
    "split = 0.8\n",
    "vsamples = [500, 200]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# model properties\n",
    "n_blocks = 4\n",
    "modes = 16\n",
    "width = 256\n",
    "\n",
    "# training properties\n",
    "trainable_blocks = True\n",
    "learning_rate = 0.001\n",
    "epochs = 250\n",
    "step_size = 100\n",
    "gamma = 0.5\n",
    "batch_size = 20\n",
    "nonlinearity = F.relu\n",
    "# I/O properties\n",
    "output_freq = 1\n",
    "checkpoint_freq = 1000\n",
    "\n",
    "now = datetime.now()\n",
    "ts = now.strftime(\"%m%d%Y%H%M%S\")\n",
    "\n",
    "model_name = \"{}_{}_{}_{}_{}_{}_{}\".format(n_blocks,\n",
    "                                           train_ds_name, \n",
    "                                           ss_rate[0], \n",
    "                                           vsamples[0], \n",
    "                                           modes, \n",
    "                                           width, \n",
    "                                           ts)\n",
    "model_path = PATH+\"model/{}\".format(model_name)\n",
    "train_err_path = PATH+\"results/{}_train.txt\".format(model_name)\n",
    "test_err_path = PATH+\"results/{}_test.txt\".format(model_name)\n",
    "fig_path = PATH+\"figures/{}_plot.png\".format(model_name)\n",
    "\n",
    "checkpt = PATH+\"log/{}.pt\".format(model_name)\n",
    "path_log = PATH+\"log/{}.txt\".format(model_name)\n",
    "\n",
    "\n",
    "run_properties = (\"run properties:\\n\"\n",
    "                \"num. epochs: {}\\n\"\n",
    "                \"learning rate: {}\\n\"\n",
    "                \"step size: {}\\n\"\n",
    "                \"gamma: {}\\n\"\n",
    "                \"n_blocks: {}\\n\"\n",
    "                \"training dataset: {}\\n\"\n",
    "                \"subsampling rate: {}\\n\"\n",
    "                \"training samples: {}\\n\"\n",
    "                \"modes: {}\\n\"\n",
    "                \"width: {}\\n\\n\").format(epochs, \n",
    "                                        learning_rate, \n",
    "                                        step_size, \n",
    "                                        gamma, \n",
    "                                        n_blocks, \n",
    "                                        train_ds_name, \n",
    "                                        ss_rate[0], \n",
    "                                        vsamples[0], \n",
    "                                        modes, \n",
    "                                        width,\n",
    "                                        )\n",
    "print(run_properties)\n",
    "\n",
    "train_log = []\n",
    "train_log.append(run_properties)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x_train, y_train, x_test, y_test, mat_info, ds_info = mat_to_tensor1d(\n",
    "                                                            TRAIN_PATH, \n",
    "                                                            TEST_PATH, \n",
    "                                                            ss_rate,\n",
    "                                                            x_name, \n",
    "                                                            y_name,\n",
    "                                                            vsamples=vsamples,\n",
    "                                                            )\n",
    "print(mat_info)\n",
    "print(ds_info)\n",
    "train_log.append(mat_info)\n",
    "train_log.append(ds_info)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Add spatial coordinate channel"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ntrain = x_train.shape[0]\n",
    "ntest = x_test.shape[0]\n",
    "train_esamples = x_train.shape[1]\n",
    "test_esamples = x_test.shape[1]\n",
    "\n",
    "tr_domain = np.linspace(0, 2*np.pi, train_esamples).reshape(1, train_esamples, 1)\n",
    "tr_domain = torch.tensor(tr_domain, dtype=torch.float)\n",
    "\n",
    "x_train = torch.cat([x_train.view(ntrain,\n",
    "                                  train_esamples,\n",
    "                                  1), \n",
    "                     tr_domain.repeat(ntrain,1,1)],\n",
    "                     dim=2)\n",
    "\n",
    "tst_domain = np.linspace(0, 2*np.pi, test_esamples).reshape(1, test_esamples, 1)\n",
    "tst_domain = torch.tensor(tst_domain, dtype=torch.float)\n",
    "x_test = torch.cat([x_test.view(ntest,\n",
    "                                test_esamples,\n",
    "                                1), \n",
    "                    tst_domain.repeat(ntest,1,1)],\n",
    "                    dim=2)\n",
    "\n",
    "data_shape = (\"x_train shape: {}\\n\"\n",
    "             \"x_test shape: {}\\n\"\n",
    "             \"y_train shape: {}\\n\"\n",
    "             \"y_test shape: {}\\n\\n\"\n",
    "             ).format(x_train.shape, \n",
    "                      x_test.shape, \n",
    "                      y_train.shape, \n",
    "                      y_test.shape)\n",
    "print(data_shape)\n",
    "train_log.append(data_shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Make dataloaders from tensors"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ntrain = ntrain - (ntrain % batch_size)\n",
    "ntest = ntest - (ntest % batch_size)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "                            torch.utils.data.TensorDataset(\n",
    "                                    x_train[:ntrain,:,:], \n",
    "                                    y_train[:ntrain,:]), \n",
    "                            batch_size=batch_size,\n",
    "                            pin_memory=True,\n",
    "                            shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "                            torch.utils.data.TensorDataset(\n",
    "                                    x_test[:ntest,:,:], \n",
    "                                    y_test[:ntest,:]), \n",
    "                            batch_size=batch_size, \n",
    "                            pin_memory=True,\n",
    "                            shuffle=False)\n",
    "\n",
    "train_features, train_labels = next(iter(train_loader))\n",
    "batch_info = (\"x batch shape: {}\\n\"\n",
    "              \"y batch shape: {}\\n\"\n",
    "             ).format(train_features.size(), \n",
    "                      train_labels.size())\n",
    "print(batch_info)\n",
    "train_log.append(batch_info)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Model, optimizer, loss"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "device = torch.device('cpu')\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    \n",
    "gpu = \"using device {}\\n\".format(device)\n",
    "print(gpu)\n",
    "train_log.append(gpu)\n",
    "\n",
    "\n",
    "kernel = FourierKernel1d(n_blocks, \n",
    "                         modes, \n",
    "                         width, \n",
    "                         nonlinearity,\n",
    "                         trainable_blocks).to(device)\n",
    "model = OperatorNet(kernel,\n",
    "                    name=\"Fourier{}blocks1d\".format(n_blocks)).to(device)\n",
    "\n",
    "print(model.name())\n",
    "train_log.append(model.name())\n",
    "print(\"model parameter count:\", model.param_count)\n",
    "train_log.append((\"\\nmodel parameter count: {}\\n\"\n",
    "                ).format(model.param_count))\n",
    "\n",
    "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), \n",
    "                             lr=learning_rate, \n",
    "                             weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(\n",
    "                                    optimizer, \n",
    "                                    step_size=step_size, \n",
    "                                    gamma=gamma)\n",
    "\n",
    "lp_loss = LpLoss(size_average=False)\n",
    "normalize = False\n",
    "if normalize:\n",
    "    y_normalizer.to(device)\n",
    "\n",
    "RFM = False\n",
    "# Random Features model uses average\n",
    "if RFM:\n",
    "    lp_loss = LpLoss(size_average=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Training loop"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tr_err = []\n",
    "tst_err = []\n",
    "\n",
    "start_time = default_timer()\n",
    "for ep in range(epochs):\n",
    "        \n",
    "    model.train()\n",
    "    t1 = default_timer()\n",
    "    train_mse = 0\n",
    "    \n",
    "    for x, y in train_loader:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        if normalize:\n",
    "            out = y_normalizer.decode(out)\n",
    "            y = y_normalizer.decode(y)\n",
    "        else:\n",
    "            out = model(x)\n",
    "        \n",
    "        #loss = F.mse_loss(model(x).view(-1), y.view(-1), reduction='mean')\n",
    "        loss = lp_loss(out.view(batch_size,-1), \n",
    "                       y.view(batch_size,-1))\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        train_mse += loss.item()\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    model.eval()\n",
    "    abs_err = 0.0\n",
    "    rel_err = 0.0\n",
    "    with torch.no_grad():\n",
    "        for x, y in test_loader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            out = model(x)\n",
    "\n",
    "            if normalize:\n",
    "                out = y_normalizer.decode(model(x))\n",
    "\n",
    "            abs_err += lp_loss.abs(out.view(batch_size,-1), \n",
    "                               y.view(batch_size,-1)).item()\n",
    "            rel_err += lp_loss(out.view(batch_size,-1), \n",
    "                               y.view(batch_size,-1)).item()\n",
    "\n",
    "    train_mse/= ntrain\n",
    "    abs_err /= ntest\n",
    "    rel_err /= ntest\n",
    "    \n",
    "    tr_err.append(train_mse)\n",
    "    tst_err.append(rel_err)\n",
    "\n",
    "    t2 = default_timer()\n",
    "    \n",
    "    epoch_vals = (\"epoch {} \\n\"\n",
    "                    \"values:\\n\"\n",
    "                    \"elapsed time: {:.3f}\\n\"\n",
    "                    \"training mse: {:.5f}\\n\"\n",
    "                    \"absolute error: {:5f}\\n\"\n",
    "                    \"relative error: {:.5f}\\n\\n\"\n",
    "                 ).format(ep, t2-t1, train_mse, abs_err, rel_err)\n",
    "    train_log.append(epoch_vals)\n",
    "    \n",
    "    if ep % output_freq == 0:\n",
    "        print(epoch_vals)\n",
    "        \n",
    "    if ep % checkpoint_freq == 0:\n",
    "        torch.save({\n",
    "                    'epoch': ep,\n",
    "                    'model_state_dict': model.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'log': train_log,\n",
    "                    }, checkpt)\n",
    "\n",
    "end_time = default_timer()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "final_vals = (\"final values:\\n\"\n",
    "            \"elapsed time: {:.3f}\\n\" \n",
    "            \"training mse: {:.5f}\\n\"\n",
    "            \"relative error: {:.5f}\\n\\n\"\n",
    "             ).format(end_time - start_time, \n",
    "                      train_mse, \n",
    "                      rel_err)\n",
    "print(final_vals)\n",
    "train_log.append(final_vals)\n",
    "\n",
    "fd = open(path_log, \"a\")\n",
    "for string in train_log:\n",
    "    fd.write(string)\n",
    "fd.close()\n",
    "\n",
    "torch.save(model, model_path)\n",
    "np.savetxt(train_err_path, tr_err)\n",
    "np.savetxt(test_err_path, tst_err)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Visualize"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "PATH = '../'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "name = \"burgers_4blocks_samples\"\n",
    "data = []\n",
    "dir = \"../results/final/\"+name\n",
    "for filename in os.listdir(dir):\n",
    "    f = os.path.join(dir, filename)\n",
    "    if os.path.isfile(f):\n",
    "        data.append(np.loadtxt(f))\n",
    "\n",
    "labels = ['n = 400', 'n = 600', 'n = 800']\n",
    "fig, ax = plt.subplots()\n",
    "for arr, l in zip(data, labels):\n",
    "    ax.plot(arr, label=l)\n",
    "\n",
    "ax.set_xlabel('Epochs')\n",
    "ax.set_ylabel('Relative Error')\n",
    "ax.set_ylim(0, 0.10)\n",
    "ax.legend()\n",
    "fig.show()\n",
    "\n",
    "fig.suptitle('Resolution: 4096, Blocks:4, Modes: 16, Width:64\\nModel parameter count: 558,017')\n",
    "\n",
    "save_path = \"../figures/\"+name+\".png\"\n",
    "plt.savefig(save_path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "burgers4 = np.loadtxt('../results/final/4_True_burgers_data_R10_original_4_600_16_64__05242021091147_test.txt')\n",
    "burgers3 = np.loadtxt('../results/final/3_True_burgers_data_R10_original_2_600_16_64__05242021092125_test.txt')\n",
    "burgers2 = np.loadtxt('../results/final/2_True_burgers_data_R10_original_2_600_16_64__05242021093013_test.txt')\n",
    "burgers1 = np.loadtxt('../results/final/1_True_burgers_data_R10_original_2_600_16_64__05242021094828_test.txt')\n",
    "\n",
    "arrays = [burgers4, burgers3, burgers2, burgers1]\n",
    "labels = ['4 blocks (param. count: 558,017)', '3 blocks (param. count: 418,561)', '2 blocks (param. count: 279,105)', '1 block (param. count: 139,649)']\n",
    "fig, ax = plt.subplots()\n",
    "for arr, l in zip(arrays, labels):\n",
    "    ax.plot(arr, label=l)\n",
    "ax.set_xlabel(\"Epochs\")\n",
    "ax.set_ylabel(\"Relative Error\")\n",
    "ax.set_ylim(0, 0.06)\n",
    "ax.legend()\n",
    "fig.show()\n",
    "\n",
    "fig.suptitle(\"Modes: 16, Width:64, Res. = 4096, Samples = 600\")\n",
    "\n",
    "im_path = \"../figures/burgers_blocks.png\"\n",
    "plt.savefig(im_path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test800 = ('../results/_04212021135651fullres_darcy_e421_N1024_g2_t3_f1_2104130943_test.txt')\n",
    "test800 = np.loadtxt(test800)\n",
    "test600 = ('../results/_04212021140837fullres_darcy_e421_N1024_g2_t3_f1_2104130943_test.txt')\n",
    "test600 = np.loadtxt(test600)\n",
    "test400 = ('../results/_04212021141821fullres_darcy_e421_N1024_g2_t3_f1_2104130943_test.txt')\n",
    "test400 = np.loadtxt(test400)\n",
    "test200 = ('../results/_04212021143939fullres_darcy_e421_N1024_g2_t3_f1_2104130943_test.txt')\n",
    "test200 = np.loadtxt(test200)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(test200, label='n = 200')\n",
    "ax.plot(test400, label='n = 400')\n",
    "ax.plot(test600, label='n = 600')\n",
    "ax.plot(test800, label='n = 800')\n",
    "ax.set_xlabel('Epochs')\n",
    "ax.set_ylabel('Relative Error')\n",
    "ax.set_ylim(0, 0.10)\n",
    "ax.legend()\n",
    "fig.show()\n",
    "\n",
    "fig.suptitle(\"Resolution: 211 (421//2), Blocks: 4, Modes: 12, Width: 32\\nModel parameter count: 2,368,001\")\n",
    "im_path =\"../figures/darcy200to800_ss_error_final.png\"\n",
    "plt.savefig(im_path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "blocks4darcy = np.loadtxt(PATH+'results/_04212021062545fullres_darcy_e421_N1024_g2_t3_f1_2104130943_test.txt')\n",
    "blocks3darcy = np.loadtxt(PATH+'results/_04212021071540fullres_darcy_e421_N1024_g2_t3_f1_2104130943_test.txt')\n",
    "blocks2darcy = np.loadtxt(PATH+'results/_04212021075009fullres_darcy_e421_N1024_g2_t3_f1_2104130943_test.txt')\n",
    "\n",
    "#blocks1darcy = np.loadtxt(PATH+'results/.txt')\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(blocks4darcy, label='blocks = 4, parameters = 2,368,001')\n",
    "ax.plot(blocks3darcy, label='blocks = 3, parameters = 1,776,033')\n",
    "ax.plot(blocks2darcy, label='blocks = 2, parameters = 1,184,065')\n",
    "#ax.plot(blocks2darcy, label='blocks = 1, parameters = ')\n",
    "\n",
    "ax.set_xlabel('Epochs')\n",
    "ax.set_ylim(0, 0.10)\n",
    "ax.legend()\n",
    "fig.show()\n",
    "\n",
    "fig.suptitle('Resolution: 421, Modes: 12, Width: 32, Samples: 820')\n",
    "#fig.tight_layout()\n",
    "im_path = PATH+\"figures/darcyblocks_errorplot.png\"\n",
    "plt.savefig(im_path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Testing on different datasets:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_ds_name = \"burgers_e4096_N1000_g2.5_t7_v100_s49_per_2104291732\"\n",
    "test_dir = \"burgers_e4096_N400_g2.5_t7_v100_s49_dir_2104300546\"\n",
    "test_per = \"burgers_e4096_N400_g2.5_t7_v100_s49_per_2104300508\"\n",
    "test_neu = \"burgers_e4096_N400_g2.5_t7_v100_s49_neu_2104300435\"\n",
    "\n",
    "TEST_PATH = [PATH+'data/shared_data/'+test_dir+'.mat',\n",
    "             PATH+'data/shared_data/'+test_per+'.mat',\n",
    "             PATH+'data/shared_data/'+test_neu+'.mat']\n",
    "\n",
    "train_ds_name = 'burgers_data_R10_original'\n",
    "test_ds_name = 'burgers_data_R10_original'\n",
    "TRAIN_PATH = PATH+'data/shared_data/'+train_ds_name+'.mat'\n",
    "TEST_PATH = PATH+'data/shared_data/'+test_ds_name+'.mat'\n",
    "\n",
    "# field name in the matlab file\n",
    "x_name = \"a\"\n",
    "y_name = \"u\"\n",
    "\n",
    "# dataset properties\n",
    "ss_rate = [2, 2]\n",
    "split = 0.8\n",
    "vsamples = [600, 200]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x_train, y_train, x_test, y_test, mat_info, ds_info = mat_to_tensor1d(\n",
    "                                                            TRAIN_PATH, \n",
    "                                                            TEST_PATH, \n",
    "                                                            ss_rate,\n",
    "                                                            x_name, \n",
    "                                                            y_name,\n",
    "                                                            vsamples=vsamples,\n",
    "                                                            )\n",
    "print(mat_info)\n",
    "print(ds_info)\n",
    "\n",
    "ntrain = x_train.shape[0]\n",
    "ntest = x_test.shape[0]\n",
    "train_esamples = x_train.shape[1]\n",
    "test_esamples = x_test.shape[1]\n",
    "\n",
    "tr_domain = np.linspace(0, 2*np.pi, train_esamples).reshape(1, train_esamples, 1)\n",
    "tr_domain = torch.tensor(tr_domain, dtype=torch.float)\n",
    "\n",
    "x_train = torch.cat([x_train.view(ntrain,\n",
    "                                  train_esamples,\n",
    "                                  1), \n",
    "                     tr_domain.repeat(ntrain,1,1)],\n",
    "                     dim=2)\n",
    "\n",
    "tst_domain = np.linspace(0, 2*np.pi, test_esamples).reshape(1, test_esamples, 1)\n",
    "tst_domain = torch.tensor(tst_domain, dtype=torch.float)\n",
    "x_test = torch.cat([x_test.view(ntest,\n",
    "                                test_esamples,\n",
    "                                1), \n",
    "                    tst_domain.repeat(ntest,1,1)],\n",
    "                    dim=2)\n",
    "\n",
    "data_shape = (\"x_train shape: {}\\n\"\n",
    "             \"x_test shape: {}\\n\"\n",
    "             \"y_train shape: {}\\n\"\n",
    "             \"y_test shape: {}\\n\\n\"\n",
    "             ).format(x_train.shape, \n",
    "                      x_test.shape, \n",
    "                      y_train.shape, \n",
    "                      y_test.shape)\n",
    "print(data_shape)\n",
    "\n",
    "ntest = ntest - (ntest % batch_size)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "                            torch.utils.data.TensorDataset(\n",
    "                                    x_test[:ntest,:,:], \n",
    "                                    y_test[:ntest,:]), \n",
    "                            batch_size=batch_size, \n",
    "                            pin_memory=True,\n",
    "                            shuffle=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "eval_device = 'cpu'\n",
    "lp_loss = LpLoss(size_average=False)\n",
    "\n",
    "#model = torch.load('../model/fullres_burgers_data_R10_04242021095651_04242021095651', \n",
    " #                  map_location=torch.device(eval_device))\n",
    "model = torch.load('../model/1_burgers_data_R10_2_800_16_256__04292021134321',map_location=torch.device('cpu'))\n",
    "\"\"\"\n",
    "training dataset: burgers_data_R10\n",
    "modes: 16\n",
    "width: 1024\n",
    "layers: 4\n",
    "train vsamples: 500\n",
    "train esamples: 1024\n",
    "viscosity: 1/10\n",
    "\n",
    "x_train shape: torch.Size([500, 1024, 2])\n",
    "x_test shape: torch.Size([200, 1024, 2])\n",
    "y_train shape: torch.Size([500, 1024])\n",
    "y_test shape: torch.Size([200, 1024])\n",
    "model parameter count: 142,621,697\n",
    "\"\"\"\n",
    "model.eval()\n",
    "rel_err = 0.0\n",
    "with torch.no_grad():\n",
    "    x, y = next(iter(test_loader))\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    out = model(x)\n",
    "    rel_err = lp_loss(out.view(-1), y.view(-1)).item()\n",
    "    rel_err /= batch_size"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sample_x = x.cpu()[0,:,0]\n",
    "sample_y = y.cpu()[0,:]\n",
    "sample_approx = out.cpu()[0,:]\n",
    "\n",
    "sample_x = sample_x.numpy().reshape((train_esamples))\n",
    "sample_y = sample_y.numpy().reshape((train_esamples))\n",
    "sample_approx = sample_approx.detach().numpy().reshape(\n",
    "                                        (train_esamples))\n",
    "\n",
    "_min = np.min(np.min(sample_y))\n",
    "_max = np.max(np.max(sample_y))\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "plt.plot(sample_x, label='Input', c='orange')\n",
    "plt.plot(sample_y, label='Ground Truth', linewidth=5.0)\n",
    "plt.plot(sample_approx, 'pink', label='Approximation', linestyle='--')\n",
    "plt.title('Ground Truth')\n",
    "plt.legend()\n",
    "\n",
    "plt.plot((sample_approx - sample_y)**2)\n",
    "plt.title('Absolute Error')\n",
    "\n",
    "plt.suptitle('')\n",
    "plt.savefig(fig_path)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "device = 'cpu'\n",
    "lp_loss = LpLoss(size_average=False)\n",
    "#model = torch.load(PATH+'model/1_burgers_data_R10_2_800_16_256__04292021134321',map_location=torch.device('cpu'))\n",
    "#choose dataset\n",
    "# data_loader = \n",
    "model = torch.load('../model/fullres_burgers_data_R10_04242021095651_04242021095651', map_location=torch.device('cpu'))\n",
    "\"\"\"\n",
    "modes: 16\n",
    "width: 1024\n",
    "layers: 4\n",
    "train vsamples: 500\n",
    "train esamples: 1024\n",
    "viscosity: 1/100\n",
    "\n",
    "x_train shape: torch.Size([500, 1024, 2])\n",
    "x_test shape: torch.Size([200, 1024, 2])\n",
    "y_train shape: torch.Size([500, 1024])\n",
    "y_test shape: torch.Size([200, 1024])\n",
    "model parameter count: 142,621,697\n",
    "\n",
    "\"\"\"\n",
    "model.eval()\n",
    "rel_err = 0.0\n",
    "with torch.no_grad():\n",
    "    x, y = next(iter(test_loader))\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    out = model(x)\n",
    "    rel_err = lp_loss(out.view(-1), y.view(-1)).item()\n",
    "    rel_err /= batch_size\n",
    "    \n",
    "sample_x = x.cpu()[0,:,0]\n",
    "sample_y = y.cpu()[0,:]\n",
    "sample_approx = out.cpu()[0,:]\n",
    "\n",
    "sample_x = sample_x.numpy().reshape((train_esamples))\n",
    "sample_y = sample_y.numpy().reshape((train_esamples))\n",
    "sample_approx = sample_approx.detach().numpy().reshape(\n",
    "                                        (train_esamples))\n",
    "\n",
    "_min = np.min(np.min(sample_y))\n",
    "_max = np.max(np.max(sample_y))\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "plt.plot(sample_x, label='Input', c='orange')\n",
    "plt.plot(sample_y, label='Ground Truth', linewidth=5.0)\n",
    "plt.plot(sample_approx, 'pink', label='Approximation', linestyle='--')\n",
    "plt.title('Ground Truth')\n",
    "plt.legend()\n",
    "\n",
    "plt.plot((sample_approx - sample_y)**2)\n",
    "plt.title('Absolute Error')\n",
    "\n",
    "plt.suptitle('')\n",
    "plt.savefig(fig_path)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "FNO_1d.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:ndmd-env] *",
   "language": "python",
   "name": "conda-env-ndmd-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}